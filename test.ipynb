{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import proceso_imagenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imagenes, clases = proceso_imagenes.cargar_numeros(\"./nums\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20.5517241379 9.07473266215\n",
      "1 2.25925925926 1.64637857562\n",
      "2 4.94 2.8171616922\n",
      "3 10.38 6.69593906782\n",
      "4 4.52380952381 2.38285638156\n",
      "5 6.72549019608 5.66059108454\n",
      "6 10.6041666667 6.56613655855\n",
      "7 4.20754716981 2.1399919817\n",
      "8 11.320754717 7.29893655967\n",
      "9 3.41463414634 2.55644198015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "diccionario_numero_rectas = dict([ (key,[]) for key in range(0,10)])\n",
    "\n",
    "numero_rectas = np.fromiter(map(proceso_imagenes.contar_rectas,imagenes),dtype=int)\n",
    "\n",
    "for num, cl in zip(numero_rectas,clases):\n",
    "    diccionario_numero_rectas[cl].append(num)\n",
    "    #print(\"Numero:\",cl,\"numero rectas\",num)\n",
    "\n",
    "for key, value in diccionario_numero_rectas.items():\n",
    "    print(key,np.mean(value),np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 198.551724138 7.25204469097\n",
      "1 204.462962963 6.60727142361\n",
      "2 197.9 6.89129886161\n",
      "3 199.94 6.60729899429\n",
      "4 201.0 7.92524597786\n",
      "5 198.039215686 6.47456799774\n",
      "6 199.583333333 7.11756434619\n",
      "7 201.905660377 6.31340039629\n",
      "8 195.320754717 6.88935077837\n",
      "9 200.0 5.25913838812\n"
     ]
    }
   ],
   "source": [
    "diccionario_intensidades = dict([ (key,[]) for key in range(0,10)])\n",
    "\n",
    "intensidades_medias = np.fromiter(map(proceso_imagenes.intensidad_media, imagenes),dtype=int)\n",
    "\n",
    "for num, cl in zip(intensidades_medias,clases):\n",
    "    diccionario_intensidades[cl].append(num)\n",
    "    #print(\"Numero:\",cl,\"intwensidad\",num)\n",
    "\n",
    "for key, value in diccionario_intensidades.items():\n",
    "    print(key,np.mean(value),np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 219.068965517 9.95310048551\n",
      "1 230.203703704 8.02399094759\n",
      "2 220.22 8.78245979211\n",
      "3 221.96 9.61864855372\n",
      "4 222.023809524 10.8682326404\n",
      "5 218.117647059 8.5832647448\n",
      "6 218.979166667 9.79474685595\n",
      "7 222.056603774 8.31551197516\n",
      "8 214.0 9.74389019983\n",
      "9 220.365853659 8.27501705123\n"
     ]
    }
   ],
   "source": [
    "diccionario_intensidades_umbralizadas = dict([ (key,[]) for key in range(0,10)])\n",
    "\n",
    "intensidades_medias_umbralizadas = np.fromiter(map(proceso_imagenes.intensidad_media_umbralizada,imagenes),\n",
    "                                               dtype=int)\n",
    "\n",
    "for num, cl in zip(intensidades_medias_umbralizadas,clases):\n",
    "    diccionario_intensidades_umbralizadas[cl].append(num)\n",
    "    #print(\"Numero:\",cl,\"intwensidad\",num)\n",
    "\n",
    "for key, value in diccionario_intensidades_umbralizadas.items():\n",
    "    print(key,np.mean(value),np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 228.086206897 2.47946380994\n",
      "1 227.851851852 2.36805442417\n",
      "2 227.24 2.46219414344\n",
      "3 227.72 2.00039996001\n",
      "4 228.333333333 2.08927723509\n",
      "5 227.117647059 3.59546042116\n",
      "6 227.791666667 3.31636305143\n",
      "7 227.679245283 2.3373391169\n",
      "8 226.811320755 2.35569645812\n",
      "9 226.268292683 1.93837234013\n"
     ]
    }
   ],
   "source": [
    "diccionario_intensidades_median = dict([ (key,[]) for key in range(0,10)])\n",
    "\n",
    "intensidades_median = np.fromiter(map(proceso_imagenes.intensidad_mediana, imagenes),dtype=int)\n",
    "\n",
    "for num, cl in zip(intensidades_median,clases):\n",
    "    diccionario_intensidades_median[cl].append(num)\n",
    "    #print(\"Numero:\",cl,\"intwensidad\",num)\n",
    "\n",
    "for key, value in diccionario_intensidades_median.items():\n",
    "    print(key,np.mean(value),np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255.0 0.0\n",
      "1 255.0 0.0\n",
      "2 255.0 0.0\n",
      "3 255.0 0.0\n",
      "4 255.0 0.0\n",
      "5 255.0 0.0\n",
      "6 255.0 0.0\n",
      "7 255.0 0.0\n",
      "8 255.0 0.0\n",
      "9 255.0 0.0\n"
     ]
    }
   ],
   "source": [
    "diccionario_intensidades_median_umbralizada = dict([ (key,[]) for key in range(0,10)])\n",
    "\n",
    "intensidades_median_umbralizada = np.fromiter(map(proceso_imagenes.intensidad_mediana_umbralizada, imagenes),dtype=int)\n",
    "\n",
    "for num, cl in zip(intensidades_median_umbralizada,clases):\n",
    "    diccionario_intensidades_median_umbralizada[cl].append(num)\n",
    "    #print(\"Numero:\",cl,\"intwensidad\",num)\n",
    "\n",
    "for key, value in diccionario_intensidades_median_umbralizada.items():\n",
    "    print(key,np.mean(value),np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 202.620689655 42.2442926511\n",
      "1 211.425925926 39.8253603605\n",
      "2 222.62 40.295850903\n",
      "3 227.38 41.1785818114\n",
      "4 239.380952381 52.0686142467\n",
      "5 230.019607843 35.4619321969\n",
      "6 226.229166667 36.9601359481\n",
      "7 226.20754717 40.1536475895\n",
      "8 225.339622642 34.6431639347\n",
      "9 244.975609756 51.0310703084\n",
      "0 165.982758621 32.5653144117\n",
      "1 113.12962963 42.5136345433\n",
      "2 160.3 31.1302104073\n",
      "3 146.74 29.6781468424\n",
      "4 139.833333333 25.0949783126\n",
      "5 161.0 27.5360725979\n",
      "6 149.020833333 32.4919795125\n",
      "7 149.471698113 28.7904621088\n",
      "8 147.433962264 26.9139154819\n",
      "9 141.926829268 30.6621163286\n"
     ]
    }
   ],
   "source": [
    "diccionario_altos = dict([ (key,[]) for key in range(0,10)])\n",
    "diccionario_anchos = dict([ (key,[]) for key in range(0,10)])\n",
    "\n",
    "altos = np.fromiter(map(proceso_imagenes.alto_numero, imagenes),dtype=int)\n",
    "anchos = np.fromiter(map(proceso_imagenes.ancho_numero, imagenes),dtype=int)\n",
    "\n",
    "for al,an, cl in zip(altos,anchos,clases):\n",
    "    diccionario_altos[cl].append(al)\n",
    "    diccionario_anchos[cl].append(an)\n",
    "    #print(\"Numero:\",cl,\"intwensidad\",num)\n",
    "\n",
    "for key, value in diccionario_altos.items():\n",
    "    print(key,np.mean(value),np.std(value))\n",
    "    \n",
    "for key, value in diccionario_anchos.items():\n",
    "    print(key,np.mean(value),np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#n_rectas altos anchos i_m i_m_u\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from multiprocessing import Pool\n",
    "size_dataset = 500\n",
    "\n",
    "p = Pool(2)\n",
    "\n",
    "#numero_rectas = np.fromiter(p.map(proceso_imagenes.contar_rectas,imagenes),dtype=int)\n",
    "#altos = np.fromiter(p.map(proceso_imagenes.alto_numero, imagenes),dtype=int)\n",
    "#anchos = np.fromiter(p.map(proceso_imagenes.ancho_numero, imagenes),dtype=int)\n",
    "#intensidades_medias_umbralizadas = np.fromiter(p.map(proceso_imagenes.intensidad_media_umbralizada,imagenes),\n",
    "#                                              dtype=int)\n",
    "#intensidades_medias = np.fromiter(p.map(proceso_imagenes.intensidad_media, imagenes),dtype=int)\n",
    "\n",
    "def estandarizar_x(imagen):\n",
    "    return proceso_imagenes.estandarizar(proceso_imagenes.proyeccion_x(imagen))\n",
    "\n",
    "def estandarizar_y(imagen):\n",
    "    return proceso_imagenes.estandarizar(proceso_imagenes.proyeccion_y(imagen))\n",
    "\n",
    "u = np.asarray(list(p.map(estandarizar_x,imagenes)))\n",
    "v = np.asarray(list(p.map(estandarizar_y,imagenes)))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reduce(lambda x,y: np.vstack((x,y)),[numero_rectas,altos,anchos,intensidades_medias,intensidades_medias_umbralizadas]).T\n",
    "print(u.shape)\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset = reduce(lambda x,y: np.hstack((x,y)),[dataset,u,v])\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x_1 = np.arange(v.shape[1])\n",
    "x_2 = np.arange(u.shape[1])[::-1]\n",
    "\n",
    "for c in np.unique(clases):\n",
    "    print(c)\n",
    "    for cl, vv, uu in zip(clases,v,u):\n",
    "        if cl ==c:\n",
    "            f, ax = plt.subplots(1, 6,figsize=(10,10))\n",
    "            \n",
    "            hist_1 = proceso_imagenes.convolucion(vv)\n",
    "            hist_2 = proceso_imagenes.convolucion(uu)\n",
    "            \n",
    "            ax[0].plot(x_1,vv)\n",
    "            ax[1].plot(uu,x_2)\n",
    "            \n",
    "            ax[0].plot(x_1, hist_1)\n",
    "            ax[1].plot(hist_2, x_2)\n",
    "            \n",
    "            estirado_1 = proceso_imagenes.estirar(hist_1)\n",
    "            estirado_2 = proceso_imagenes.estirar(hist_2)\n",
    "            \n",
    "            x_1_estirado = np.arange(estirado_1.shape[0])\n",
    "            x_2_estirado = np.arange(estirado_2.shape[0])[::-1]\n",
    "            \n",
    "            ax[2].plot(x_1_estirado, estirado_1)\n",
    "            ax[3].plot(estirado_2, x_2_estirado)\n",
    "            \n",
    "            resample_1, n_bins_1 = proceso_imagenes.resample(estirado_1)\n",
    "            resample_2, n_bins_2 = proceso_imagenes.resample(estirado_2)\n",
    "            \n",
    "            reasmple_x_1 = np.arange(n_bins_1)\n",
    "            reasmple_x_2 = np.arange(n_bins_2)\n",
    "            \n",
    "            \n",
    "            ax[4].plot(reasmple_x_1, resample_1)\n",
    "            ax[5].plot(resample_2, reasmple_x_2)\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "last_index_train = 450\n",
    "\n",
    "dataset_train = dataset[:last_index_train]\n",
    "clases_train = clases[:last_index_train]\n",
    "\n",
    "dataset_test = dataset[last_index_train:size_dataset]\n",
    "clases_test = clases[last_index_train:size_dataset]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "#model = GaussianNB()\n",
    "#model = LinearRegression()\n",
    "model.fit(dataset_train,clases_train)\n",
    "print(model.score(dataset_test,clases_test))\n",
    "\n",
    "\n",
    "for row,c in zip(dataset_test,clases_test):\n",
    "    prediccion = model.predict(row.reshape(1,-1))\n",
    "    if prediccion == c:\n",
    "        print(\"OK clase:\" ,c)\n",
    "    else:\n",
    "        print(\"ERR clase:\", c, \"prediccion\",prediccion[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
